{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f84be-fccf-47d3-b83d-8ce95c71a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Importing Libraries:-\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "2. Importing the Data:-\n",
    "pd.set_option('display.max_columns',None)\n",
    "data=pd.read_csv(\"cellphone.csv\")\n",
    "data.rename(columns={'blue':'bluetooth','fc':'front_camera','m_dep':'mobile_depth','mobile_wt':'mobile_weight','pc':'primary_camera','px_height':'pixel_height','px_width':'pixel_width','sc_h':'screen_height','sc_w':'screen_width'},inplace=True)\n",
    "\n",
    "3. Finding the Null values:-\n",
    "data.info()\n",
    "\n",
    "4. General info about the Data:-\n",
    "data.head()\n",
    "data.tail()\n",
    "data.describe()\n",
    "\n",
    "5. Exploratory Data Analysis:-\n",
    "\n",
    "    A. Univariant Analysis\n",
    "import sweetviz as sv \n",
    "my_report=sv.analyze(data)\n",
    "my_report.show_html()\n",
    "\n",
    "    B. Bivariant Analysis\n",
    " plt.figure(figsize=(40,45), facecolor='white')\n",
    "\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data:\n",
    "    if plotnumber <= 10:\n",
    "        plt.subplot(5, 2, plotnumber)\n",
    "        sns.histplot(x=data[column], hue=data['price_range'])\n",
    "        plt.xlabel(column, fontsize=30)  # Decreased the fontsize for better visualization\n",
    "        plt.ylabel(\"price_range\", fontsize=20, rotation=90)\n",
    "        plt.xticks(rotation=45)\n",
    "    plotnumber += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "    C. Multi Variant Analysis\n",
    "sns.pairplot(data)\n",
    "\n",
    "6. Data Preprocessing and Feature Engineering:-\n",
    "data.isnull().sum()\n",
    "corr_data=data[['battery_power', 'bluetooth', 'clock_speed', 'dual_sim', 'front_camera',\n",
    "       'four_g', 'int_memory', 'mobile_depth', 'mobile_weight', 'n_cores',\n",
    "       'primary_camera', 'pixel_height', 'pixel_width', 'ram', 'screen_height',\n",
    "       'screen_width', 'talk_time', 'three_g', 'touch_screen', 'wifi',\n",
    "       'price_range']]\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(data.corr(),annot=True , linewidth=1)\n",
    "plt.figure(figsize=(20,25),facecolor='white')\n",
    "plotnumber=1\n",
    "\n",
    "for column in data:\n",
    "    if plotnumber<=9:\n",
    "        ax=plt.subplot(3,3,plotnumber)\n",
    "        sns.boxplot(data[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        plt.ylabel('Count',fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()\n",
    "# Function to replace outliers with median for a specific column\n",
    "def replace_outliers_with_median(data, front_camera ):\n",
    "    median = data[front_camera].median()\n",
    "    std_dev = data[front_camera].std()\n",
    "    threshold = 3 * std_dev\n",
    "    data[front_camera] = data[front_camera].apply(lambda x: median if abs(x - median) > threshold else x)\n",
    "    return data\n",
    "# Replace outliers with median for a specific column\n",
    "data = replace_outliers_with_median(data, 'front_camera')\n",
    "print(\"DataFrame with outliers replaced by median:\")\n",
    "print(data)\n",
    "\n",
    "7. Splitting the data  into Train and Test Split:-\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create an instance of MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the scaler fitted on the training data\n",
    "X_test = scaler.transform(X_test)\n",
    "X=data.drop('price_range',axis=1)\n",
    "y=data.price_range\n",
    "\n",
    "8. Model Creation:-\n",
    "  \n",
    "  A. Linear Regression\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Training the linear regression model\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the testing data\n",
    "predictions = linear_reg.predict(X_test)\n",
    "\n",
    "# Calculating mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculating R-squared\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "  B. Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Creating a Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(random_state=42)  # You can adjust hyperparameters like max_depth, min_samples_split, etc.\n",
    "\n",
    "# Fitting the model on the training data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the testing data\n",
    "predictions = dt.predict(X_test)\n",
    "\n",
    "# Calculating mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculating R-squared\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared:\",r2)\n",
    "\n",
    "  Hyperparameter Tuning for Decision Tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, None],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Create a Decision Tree Regressor\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=dt_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculating R-squared\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared:\",r2)\n",
    "\n",
    "  C. Support Vector Machine (SVM)\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# Creating a Support Vector Machine (SVM) regression model\n",
    "svm = SVR(kernel='linear')  # You can choose different kernels like 'linear', 'poly', 'rbf', etc.\n",
    "\n",
    "# Training the model on the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the testing data\n",
    "predictions = svm.predict(X_test)\n",
    "\n",
    "# Calculating mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculating R-squared\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared:\",r2)\n",
    "\n",
    "  Hyperparameter Tuning for SVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],  # Kernel type\n",
    "    'C': [0.1, 1, 10, 100],        # Regularization parameter\n",
    "    'gamma': ['scale', 'auto']     # Kernel coefficient for 'rbf' kernel\n",
    "}\n",
    "\n",
    "# Creating a Support Vector Machine (SVM) regression model\n",
    "svm = SVR()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared:\",r2)\n",
    "\n",
    "  D. Random Forest \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming 'data' is your dataset with features and 'Price' is the target variable for a regression problem\n",
    "# Assuming you have already split your data into 'X_train', 'X_test' features and 'y_train', 'y_test' target variables\n",
    "\n",
    "# Creating a Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust the number of estimators as needed\n",
    "\n",
    "# Fitting the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the testing data\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Calculating mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculating R-squared\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared:\",r2)\n",
    "\n",
    "  E. XG Boost \n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming 'data' is your dataset with features and 'Price' is the target variable for a regression problem\n",
    "\n",
    "\n",
    "# Training the model\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',  # Use regression objective function\n",
    "    'eval_metric': 'rmse'             # Use root mean squared error (RMSE) as evaluation metric\n",
    "}\n",
    "num_rounds = 100  # Number of boosting rounds\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "xg_reg = xgb.train(params, dtrain, num_boost_round=num_rounds)\n",
    "\n",
    "# Making predictions on the testing data\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "predictions = xg_reg.predict(dtest)\n",
    "\n",
    "# Calculating mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculating R-squared\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "  F. Gradient Boosting \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbm=GradientBoostingRegressor()\n",
    "gbm.fit(X_train,y_train)\n",
    "y_gbm=gbm.predict(X_test)\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_gbm)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_gbm)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2) score\n",
    "r2 = r2_score(y_test, y_gbm)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared (R2) Score:\", r2)\n",
    "\n",
    "  Hyperparameter Tuning for Gradient Boost Method\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of boosting stages to be run\n",
    "    'learning_rate': [0.05, 0.1, 0.2],  # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': [3, 4, 5]  # Maximum depth of the individual estimators\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting Regressor\n",
    "gbm = GradientBoostingRegressor()\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
